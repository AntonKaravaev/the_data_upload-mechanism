1) Если в таблице 100 млн записей, возможно имеет смысл
    - настроить шардирование (к примеру по ФИО) - таким образом разделить большую таблицу на несколько баз данных,
        где в каждой бд будет таблица меньшего размера.
    - настроить горизонтальное партицироваиние (несколько одинаковых таблиц в одной БД с той же идеей разделения по ФИО)

2) Отправлять 10 млн записей рестом кажется плохая идея. Нужно выбирать асинхронные форматы передачи данных.

3) Kafka, RabbitMQ как вариант.

4) Для отправки 10 млн записей можно использовать стриминговые штуки,
такие как Apache Flink, Apache Spark для передачи данных в реальном времени. (Опыта у меня с этими технологиями нет)